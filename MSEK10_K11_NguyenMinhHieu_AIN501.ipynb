{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF7A66AAvd8Q7UAG2Sd9tg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhhieu9800/AIN501/blob/main/MSEK10_K11_NguyenMinhHieu_AIN501.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CztI6cKJyVid",
        "outputId": "f54dfd93-c04b-48ee-f2e1-023c212a3fc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AIN501'...\n",
            "remote: Enumerating objects: 3463, done.\u001b[K\n",
            "remote: Counting objects: 100% (193/193), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 3463 (delta 0), reused 125 (delta 0), pack-reused 3270\u001b[K\n",
            "Receiving objects: 100% (3463/3463), 83.15 MiB | 25.55 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# Kết nối đến GitHub\n",
        "!git clone https://github.com/minhhieu9800/AIN501.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import Adam\n",
        "import keras.callbacks as callbacks\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "PV5yvZg3v0uI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khai báo đường dẫn cho tập dữ liệu train và validate\n",
        "train_dir = '/content/AIN501/train'\n",
        "val_dir = '/content/AIN501/validate'\n",
        "\n",
        "# Thông số cho tập dữ liệu\n",
        "img_width, img_height = 224, 224\n",
        "input_shape = (img_width, img_height, 3)\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "num_classes = len([f for f in os.listdir(train_dir) if not f.endswith('.zip')])\n",
        "\n",
        "print(num_classes)\n",
        "\n",
        "# Tạo data generator cho tập train và validate\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Xây dựng mô hình CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# Lưu model\n",
        "model.save('logo_model.h5')\n",
        "\n",
        "# Đánh giá mô hình\n",
        "score = model.evaluate(val_generator, val_generator.samples // batch_size, workers=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwHXdLtQvFOI",
        "outputId": "47e74762-2524-47ae-f2b9-98b87c03b381"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n",
            "Found 1213 images belonging to 44 classes.\n",
            "Found 1609 images belonging to 44 classes.\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - 22s 583ms/step - loss: 3.9649 - accuracy: 0.0322 - val_loss: 3.7850 - val_accuracy: 0.0244\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 21s 576ms/step - loss: 3.7634 - accuracy: 0.0390 - val_loss: 3.7796 - val_accuracy: 0.0388\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 21s 568ms/step - loss: 3.7321 - accuracy: 0.0644 - val_loss: 3.7586 - val_accuracy: 0.0463\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 21s 563ms/step - loss: 3.6800 - accuracy: 0.0787 - val_loss: 3.7274 - val_accuracy: 0.0444\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 20s 548ms/step - loss: 3.6288 - accuracy: 0.0847 - val_loss: 3.6468 - val_accuracy: 0.0688\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 3.5039 - accuracy: 0.1245 - val_loss: 3.5622 - val_accuracy: 0.1031\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 21s 574ms/step - loss: 3.4179 - accuracy: 0.1346 - val_loss: 3.4568 - val_accuracy: 0.1150\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 20s 545ms/step - loss: 3.2624 - accuracy: 0.1592 - val_loss: 3.3373 - val_accuracy: 0.1713\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 3.0234 - accuracy: 0.2269 - val_loss: 3.1594 - val_accuracy: 0.2344\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 21s 579ms/step - loss: 2.9685 - accuracy: 0.2422 - val_loss: 3.0621 - val_accuracy: 0.2700\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 22s 588ms/step - loss: 2.7659 - accuracy: 0.2947 - val_loss: 2.9018 - val_accuracy: 0.3094\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 22s 586ms/step - loss: 2.6505 - accuracy: 0.3404 - val_loss: 2.8463 - val_accuracy: 0.3169\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 23s 611ms/step - loss: 2.5104 - accuracy: 0.3633 - val_loss: 2.6282 - val_accuracy: 0.3913\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 21s 575ms/step - loss: 2.4152 - accuracy: 0.3853 - val_loss: 2.5127 - val_accuracy: 0.4119\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 21s 575ms/step - loss: 2.2633 - accuracy: 0.4081 - val_loss: 2.4987 - val_accuracy: 0.4281\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 21s 577ms/step - loss: 2.1678 - accuracy: 0.4462 - val_loss: 2.4157 - val_accuracy: 0.4450\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 21s 575ms/step - loss: 1.9841 - accuracy: 0.4860 - val_loss: 2.3196 - val_accuracy: 0.4506\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 21s 575ms/step - loss: 1.9867 - accuracy: 0.4547 - val_loss: 2.2328 - val_accuracy: 0.4775\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 21s 577ms/step - loss: 1.8477 - accuracy: 0.4987 - val_loss: 2.1966 - val_accuracy: 0.4837\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 21s 569ms/step - loss: 1.7712 - accuracy: 0.5241 - val_loss: 2.1654 - val_accuracy: 0.4888\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 21s 565ms/step - loss: 1.8066 - accuracy: 0.5089 - val_loss: 2.1921 - val_accuracy: 0.4919\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 21s 554ms/step - loss: 1.7151 - accuracy: 0.5512 - val_loss: 2.1026 - val_accuracy: 0.5200\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 21s 567ms/step - loss: 1.6443 - accuracy: 0.5572 - val_loss: 2.0713 - val_accuracy: 0.5294\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 1.5418 - accuracy: 0.5690 - val_loss: 2.0466 - val_accuracy: 0.5337\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 21s 572ms/step - loss: 1.5065 - accuracy: 0.5851 - val_loss: 2.0882 - val_accuracy: 0.5263\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 22s 589ms/step - loss: 1.4514 - accuracy: 0.5910 - val_loss: 2.0265 - val_accuracy: 0.5531\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 21s 579ms/step - loss: 1.3926 - accuracy: 0.6130 - val_loss: 1.9043 - val_accuracy: 0.5681\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 21s 574ms/step - loss: 1.3143 - accuracy: 0.6283 - val_loss: 1.8761 - val_accuracy: 0.5694\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 21s 579ms/step - loss: 1.3246 - accuracy: 0.6367 - val_loss: 1.8780 - val_accuracy: 0.5750\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 21s 581ms/step - loss: 1.2824 - accuracy: 0.6376 - val_loss: 1.8826 - val_accuracy: 0.5744\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 22s 577ms/step - loss: 1.1934 - accuracy: 0.6765 - val_loss: 1.9036 - val_accuracy: 0.5838\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 22s 607ms/step - loss: 1.1690 - accuracy: 0.6757 - val_loss: 1.8767 - val_accuracy: 0.5931\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 21s 581ms/step - loss: 1.1794 - accuracy: 0.6698 - val_loss: 1.8255 - val_accuracy: 0.6062\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 21s 580ms/step - loss: 1.1266 - accuracy: 0.6791 - val_loss: 1.8810 - val_accuracy: 0.5944\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 21s 576ms/step - loss: 1.0991 - accuracy: 0.6782 - val_loss: 1.8262 - val_accuracy: 0.5981\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 21s 570ms/step - loss: 1.0753 - accuracy: 0.6732 - val_loss: 1.9422 - val_accuracy: 0.5844\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 21s 569ms/step - loss: 0.9728 - accuracy: 0.7189 - val_loss: 1.8351 - val_accuracy: 0.6119\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 21s 564ms/step - loss: 1.0003 - accuracy: 0.7121 - val_loss: 1.8370 - val_accuracy: 0.6062\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 21s 575ms/step - loss: 0.9513 - accuracy: 0.7307 - val_loss: 1.8096 - val_accuracy: 0.6212\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 22s 599ms/step - loss: 0.9221 - accuracy: 0.7392 - val_loss: 1.7824 - val_accuracy: 0.6175\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 21s 573ms/step - loss: 0.9710 - accuracy: 0.7214 - val_loss: 1.8539 - val_accuracy: 0.6156\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 20s 546ms/step - loss: 0.9337 - accuracy: 0.7240 - val_loss: 1.7260 - val_accuracy: 0.6306\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 22s 586ms/step - loss: 0.8880 - accuracy: 0.7466 - val_loss: 1.7783 - val_accuracy: 0.6250\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 22s 584ms/step - loss: 0.8550 - accuracy: 0.7511 - val_loss: 1.7680 - val_accuracy: 0.6275\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 21s 554ms/step - loss: 0.8620 - accuracy: 0.7401 - val_loss: 1.8569 - val_accuracy: 0.6200\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 21s 567ms/step - loss: 0.8922 - accuracy: 0.7460 - val_loss: 1.8352 - val_accuracy: 0.6256\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 21s 570ms/step - loss: 0.8393 - accuracy: 0.7561 - val_loss: 1.8124 - val_accuracy: 0.6313\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 0.7408 - accuracy: 0.7714 - val_loss: 1.8453 - val_accuracy: 0.6237\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 21s 569ms/step - loss: 0.7318 - accuracy: 0.7756 - val_loss: 1.8527 - val_accuracy: 0.6356\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 0.7786 - accuracy: 0.7644 - val_loss: 1.8499 - val_accuracy: 0.6394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-99c40bb96463>:68: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  score = model.evaluate_generator(val_generator, val_generator.samples // batch_size, workers=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.854241967201233\n",
            "Test accuracy: 0.6381250023841858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_logo(image_path):\n",
        "  class_names = sorted(os.listdir(train_dir))\n",
        "  model = load_model(\"logo_model.h5\")\n",
        "  # đường dẫn đến file ảnh logo cần dự đoán\n",
        "  # img_path = image_path\n",
        "\n",
        "  url = image_path\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # mở ảnh từ response\n",
        "  img = Image.open(BytesIO(response.content))\n",
        "\n",
        "  # Chuyển ảnh về RGB\n",
        "  img = img.convert('RGB')\n",
        "\n",
        "  img = img.resize((224, 224))\n",
        "\n",
        "  img_array = np.array(img)\n",
        "  x = np.expand_dims(img_array, axis=0)\n",
        "  x = x / 255.0\n",
        "\n",
        "  # dự đoán\n",
        "  preds = model.predict(x)\n",
        "\n",
        "  # print(class_names)\n",
        "  # print(preds)\n",
        "  # print(model.classes) \n",
        "\n",
        "  # lấy chỉ số của lớp có xác suất dự đoán cao nhất\n",
        "  class_idx = np.argmax(preds[0])\n",
        "\n",
        "  # print(class_idx)\n",
        "\n",
        "  # in ra tên của hãng xe\n",
        "  print(class_names[class_idx])\n"
      ],
      "metadata": {
        "id": "PimNjOpDENx5"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_logo(\"https://1000logos.net/wp-content/uploads/2018/03/Honda-logo.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oev78a3LFTTY",
        "outputId": "f893c1b6-28d5-49cc-ca92-f46183591aea"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "HONDA\n"
          ]
        }
      ]
    }
  ]
}